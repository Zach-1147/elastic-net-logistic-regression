pivot_wider(names_from = Food_Category, values_from = Servings_Sum, values_fill = list(Servings_Sum = 0))
View(new_rows)
View(Serving_scores)
rm(list=ls())
#Load libraries and data
install_if_needed <- function(package_name) {
if (!require(package_name, character.only = TRUE)) {
install.packages(package_name)
library(package_name, character.only = TRUE)
}
}
#Create vector with packages
packages <- c("tidyverse", "ggplot2", "readxl", "stringr")
#Nest function in loop
for (pkg in packages) {
install_if_needed(pkg)
}
#Load items file
items_file <- read_excel("PDI-P - Items File -2023.05.02-ZR.xlsx")
#Load general database
gen_db <- read_excel('Pythondb.xlsm')
#Load mixed dish database
mixed_db <- read_excel("final_mdd.xlsx")
#Load libraries and data
install_if_needed <- function(package_name) {
if (!require(package_name, character.only = TRUE)) {
install.packages(package_name)
library(package_name, character.only = TRUE)
}
}
#Create vector with packages
packages <- c("tidyverse", "ggplot2", "readxl", "stringr")
#Nest function in loop
for (pkg in packages) {
install_if_needed(pkg)
}
#Load items file
items_file <- read_excel("PDI-P - Items File -2023.05.02-ZR.xlsx")
#Load general database
gen_db <- read_excel('Pythondb.xlsm')
#Load mixed dish database
mixed_db <- read_excel("final_mdd.xlsm")
#Create columns and re-arrange columns for the processing of participant food log rows.
#Copy columns to move to very left of spreadsheet
copied_column_foodamt <- items_file$FoodAmt
copied_column_fooddesc <- items_file$Food_Description
#Remove copied columns
items_file <- items_file %>% select(-FoodAmt, -Food_Description)
#Add in copied columns, and make new columns for variables of interest
items_file <- items_file %>%
mutate(MD = "",
Food_Description = copied_column_fooddesc,
Food_Amount = copied_column_foodamt,
Reference_Amount = "",
`#_Servings` = "",
Food_Category = "")
#Specify new column order
items_file <- items_file %>%
select(user_name, MD, Food_Description, Food_Amount, Reference_Amount, `#_Servings`, Food_Category, everything())
#Create mapping lists for Food_Category and Reference_Amount
mapping_dict_FG <- setNames(gen_db$FG, gen_db$FD)
mapping_dict_RA <- setNames(gen_db$RA, gen_db$FD)
#Apply mappings to items_file based on Food_Description
items_file <- items_file %>%
mutate(Food_Category = map_chr(Food_Description, ~mapping_dict_FG[.x]),
Reference_Amount = map_chr(Food_Description, ~mapping_dict_RA[.x]))
#Convert Food_Amount and Reference_Amount to numeric
items_file <- items_file %>%
mutate(Food_Amount = as.numeric(Food_Amount),
Reference_Amount = as.numeric(Reference_Amount))
#Calculate #_Servings
items_file <- items_file %>%
mutate(`#_Servings` = Food_Amount / Reference_Amount)
#Trim whitespcae
mixed_db$Description <- trimws(mixed_db$Description)
items_file$Food_Description <- trimws(items_file$Food_Description)
#Return reference MD_ID values to MD column for identification in items file
items_file$MD <- mixed_db$MD_ID[match(items_file$Food_Description, mixed_db$Description)]
#Ensure MD and MD_ID columns are numeric to enable matching process
items_file <- items_file %>%
mutate(MD = as.numeric(MD))
mixed_db <- mixed_db %>%
mutate(MD_ID = as.numeric(MD_ID))
insert_rows_below_md <- function(items_file, mixed_db) {
results <- list() # To store the final set of rows
# Loop over each row in the items_file
for (i in 1:nrow(items_file)) {
# Add the current row from items_file to the results
results[[length(results) + 1]] <- items_file[i, ]
# Check if the current row's MD has a matching MD_ID in mixed_db
if (items_file$MD[i] %in% mixed_db$MD_ID) {
# Get the matching mixed_db row
matching_row <- mixed_db[mixed_db$MD_ID == items_file$MD[i], ]
# Split Array1 and Array2 from the matching mixed_db row
array1 <- unlist(strsplit(matching_row$array1, ";"))
array2 <- as.numeric(unlist(strsplit(matching_row$array2, ";")))
# Create and add new rows based on array1 and array2
for (j in seq_along(array1)) {
# Create a new row with default/NA values for all columns
new_row <- as.data.frame(matrix(ncol = ncol(items_file), nrow = 1))
names(new_row) <- names(items_file)
# Set the values for the specific columns
new_row$Food_Description <- array1[j]
new_row$Food_Amount <- items_file$Food_Amount[i] * array2[j]
# Retain fid, pid, and user_name from the items_file MD row
new_row$user_name <- items_file$user_name[i]
new_row$fid <- items_file$fid[i]
new_row$pid <- items_file$pid[i]
# Fill in MD to link these new rows to the original MD
new_row$MD <- items_file$MD[i]
# Add the new row to the results
results[[length(results) + 1]] <- new_row
}
}
}
# Combine all the rows into a single data frame
do.call(rbind, results)
}
# Run the function to get the final dataframe
final_df <- insert_rows_below_md(items_file, mixed_db)
#Re-apply the mapping up for food category and reference amounts
mapping_dict_FG <- setNames(gen_db$FG, gen_db$FD)
mapping_dict_RA <- setNames(gen_db$RA, gen_db$FD)
#Apply mappings to items_file based on Food_Description
final_df <- final_df %>%
mutate(Food_Category = map_chr(Food_Description, ~mapping_dict_FG[.x]),
Reference_Amount = map_chr(Food_Description, ~mapping_dict_RA[.x]))
#Convert Food_Amount and Reference_Amount to numeric
final_df <- final_df %>%
mutate(Food_Amount = as.numeric(Food_Amount),
Reference_Amount = as.numeric(Reference_Amount))
#Calculate #_Servings
final_df <- final_df %>%
mutate(`#_Servings` = Food_Amount / Reference_Amount)
View(final_df)
Serving_scores <- final_df %>%
group_by(user_name, Food_Category) %>%
summarise(Servings_Sum = sum(`#_Servings`, na.rm = TRUE), .groups = 'drop') %>%
pivot_wider(names_from = Food_Category, values_from = Servings_Sum, values_fill = list(Servings_Sum = 0))
View(Serving_scores)
rm(list=ls())
#Load libraries and data
install_if_needed <- function(package_name) {
if (!require(package_name, character.only = TRUE)) {
install.packages(package_name)
library(package_name, character.only = TRUE)
}
}
#Create vector with packages
packages <- c("tidyverse", "ggplot2", "readxl", "stringr")
#Nest function in loop
for (pkg in packages) {
install_if_needed(pkg)
}
#Load items file
items_file <- read_excel("PDI-P - Items File -2023.05.02-ZR.xlsx")
#Load general database
gen_db <- read_excel('Pythondb.xlsm')
#Load mixed dish database
mixed_db <- read_excel("final_mdd.xlsm")
#Create columns and re-arrange columns for the processing of participant food log rows.
#Copy columns to move to very left of spreadsheet
copied_column_foodamt <- items_file$FoodAmt
copied_column_fooddesc <- items_file$Food_Description
#Remove copied columns
items_file <- items_file %>% select(-FoodAmt, -Food_Description)
#Add in copied columns, and make new columns for variables of interest
items_file <- items_file %>%
mutate(MD = "",
Food_Description = copied_column_fooddesc,
Food_Amount = copied_column_foodamt,
Reference_Amount = "",
`#_Servings` = "",
Food_Category = "")
#Specify new column order
items_file <- items_file %>%
select(user_name, MD, Food_Description, Food_Amount, Reference_Amount, `#_Servings`, Food_Category, everything())
#Create mapping lists for Food_Category and Reference_Amount
mapping_dict_FG <- setNames(gen_db$FG, gen_db$FD)
mapping_dict_RA <- setNames(gen_db$RA, gen_db$FD)
#Apply mappings to items_file based on Food_Description
items_file <- items_file %>%
mutate(Food_Category = map_chr(Food_Description, ~mapping_dict_FG[.x]),
Reference_Amount = map_chr(Food_Description, ~mapping_dict_RA[.x]))
#Convert Food_Amount and Reference_Amount to numeric
items_file <- items_file %>%
mutate(Food_Amount = as.numeric(Food_Amount),
Reference_Amount = as.numeric(Reference_Amount))
#Calculate #_Servings
items_file <- items_file %>%
mutate(`#_Servings` = Food_Amount / Reference_Amount)
#Trim whitespcae
mixed_db$Description <- trimws(mixed_db$Description)
items_file$Food_Description <- trimws(items_file$Food_Description)
#Return reference MD_ID values to MD column for identification in items file
items_file$MD <- mixed_db$MD_ID[match(items_file$Food_Description, mixed_db$Description)]
#Ensure MD and MD_ID columns are numeric to enable matching process
items_file <- items_file %>%
mutate(MD = as.numeric(MD))
mixed_db <- mixed_db %>%
mutate(MD_ID = as.numeric(MD_ID))
insert_rows_below_md <- function(items_file, mixed_db) {
results <- list() # To store the final set of rows
# Loop over each row in the items_file
for (i in 1:nrow(items_file)) {
# Add the current row from items_file to the results
results[[length(results) + 1]] <- items_file[i, ]
# Check if the current row's MD has a matching MD_ID in mixed_db
if (items_file$MD[i] %in% mixed_db$MD_ID) {
# Get the matching mixed_db row
matching_row <- mixed_db[mixed_db$MD_ID == items_file$MD[i], ]
# Split Array1 and Array2 from the matching mixed_db row
array1 <- unlist(strsplit(matching_row$array1, ";"))
array2 <- as.numeric(unlist(strsplit(matching_row$array2, ";")))
# Create and add new rows based on array1 and array2
for (j in seq_along(array1)) {
# Create a new row with default/NA values for all columns
new_row <- as.data.frame(matrix(ncol = ncol(items_file), nrow = 1))
names(new_row) <- names(items_file)
# Set the values for the specific columns
new_row$Food_Description <- array1[j]
new_row$Food_Amount <- items_file$Food_Amount[i] * array2[j]
# Retain fid, pid, and user_name from the items_file MD row
new_row$user_name <- items_file$user_name[i]
new_row$fid <- items_file$fid[i]
new_row$pid <- items_file$pid[i]
# Fill in MD to link these new rows to the original MD
new_row$MD <- items_file$MD[i]
# Add the new row to the results
results[[length(results) + 1]] <- new_row
}
}
}
# Combine all the rows into a single data frame
do.call(rbind, results)
}
# Run the function to get the final dataframe
final_df <- insert_rows_below_md(items_file, mixed_db)
#Re-apply the mapping up for food category and reference amounts
mapping_dict_FG <- setNames(gen_db$FG, gen_db$FD)
mapping_dict_RA <- setNames(gen_db$RA, gen_db$FD)
#Apply mappings to items_file based on Food_Description
final_df <- final_df %>%
mutate(Food_Category = map_chr(Food_Description, ~mapping_dict_FG[.x]),
Reference_Amount = map_chr(Food_Description, ~mapping_dict_RA[.x]))
#Convert Food_Amount and Reference_Amount to numeric
final_df <- final_df %>%
mutate(Food_Amount = as.numeric(Food_Amount),
Reference_Amount = as.numeric(Reference_Amount))
#Calculate #_Servings
final_df <- final_df %>%
mutate(`#_Servings` = Food_Amount / Reference_Amount)
Serving_scores <- final_df %>%
group_by(user_name, Food_Category) %>%
summarise(Servings_Sum = sum(`#_Servings`, na.rm = TRUE), .groups = 'drop') %>%
pivot_wider(names_from = Food_Category, values_from = Servings_Sum, values_fill = list(Servings_Sum = 0))
View(Serving_scores)
Serving_scores <- final_df %>%
filter(!Food_Category %in% c("Alcohol", "Water", "MD", ".")) %>%
group_by(user_name, Food_Category) %>%
summarise(Servings_Sum = sum(`#_Servings`, na.rm = TRUE), .groups = 'drop') %>%
pivot_wider(names_from = Food_Category, values_from = Servings_Sum, values_fill = list(Servings_Sum = 0))
View(Serving_scores)
Serving_scores <- final_df %>%
group_by(user_name, Food_Category) %>%
summarise(Servings_Sum = sum(`#_Servings`, na.rm = TRUE), .groups = 'drop') %>%
pivot_wider(names_from = Food_Category, values_from = Servings_Sum, values_fill = list(Servings_Sum = 0))
View(Serving_scores)
View(final_df)
Serving_scores <- final_df %>%
filter(!Food_Category %in% c("Alcohol", "Water", "MD", ".")) %>%
group_by(user_name, Food_Category) %>%
summarise(Servings_Sum = sum(`#_Servings`, na.rm = TRUE), .groups = 'drop') %>%
pivot_wider(names_from = Food_Category, values_from = Servings_Sum, values_fill = list(Servings_Sum = 0))
all_users <- distinct(final_df, user_name)
# Left join to ensure all users are included
Serving_scores <- all_users %>%
left_join(Serving_scores, by = "user_name")
View(Serving_scores)
Serving_scores <- final_df %>%
group_by(user_name) %>%
summarise(
Alcohol_Sum = sum(Food_Amount[Food_Category == "Alcohol"], na.rm = TRUE),
Total_KCAL = sum(KCAL, na.rm = TRUE)
) %>%
left_join(
final_df %>%
filter(!Food_Category %in% c("Alcohol", "Water", "MD", ".")) %>%
group_by(user_name, Food_Category) %>%
summarise(Servings_Sum = sum(`#_Servings`, na.rm = TRUE), .groups = 'drop') %>%
pivot_wider(names_from = Food_Category, values_from = Servings_Sum, values_fill = list(Servings_Sum = 0)),
by = "user_name"
)
final_df <- final_df %>%
mutate(KCAL = as.numeric(KCAL))
Serving_scores <- final_df %>%
group_by(user_name) %>%
summarise(
Alcohol_Sum = sum(Food_Amount[Food_Category == "Alcohol"], na.rm = TRUE),
Total_KCAL = sum(KCAL, na.rm = TRUE)
) %>%
left_join(
final_df %>%
filter(!Food_Category %in% c("Alcohol", "Water", "MD", ".")) %>%
group_by(user_name, Food_Category) %>%
summarise(Servings_Sum = sum(`#_Servings`, na.rm = TRUE), .groups = 'drop') %>%
pivot_wider(names_from = Food_Category, values_from = Servings_Sum, values_fill = list(Servings_Sum = 0)),
by = "user_name"
)
# Ensure all user_names are included, even if they have zeros for all categories
all_users <- distinct(final_df, user_name)
# Left join to ensure all users are included
Serving_scores <- all_users %>%
left_join(Serving_scores, by = "user_name")
View(Serving_scores)
quintiles <- final_df %>%
group_by(Food_Category) %>%
mutate(Quintile = ntile(Amount, 5)) %>%
ungroup()
quintiles <- final_df %>%
group_by(Food_Category) %>%
mutate(Quintile = ntile(`#_Servings`, 5)) %>%
ungroup()
View(quintiles)
quintiles <- final_df %>%
group_by(Food_Category) %>%
summarise(Quintile = ntile(`#_Servings`, 5))
quintiles <- final_df %>%
group_by(Food_Category) %>%
summarise(Quintile = ntile(`#_Servings`, 5)) %>%
ungroup()
quintiles <- final_df %>%
group_by(Food_Category) %>%
mutate(Quintile = ntile(`#_Servings`, 5)) %>%
ungroup()
View(quintiles)
quintiles <- Serving_scores %>%
group_by(Food_Category) %>%
mutate(Quintile = ntile(`#_Servings`, 5)) %>%
ungroup()
rm(list=ls())
data <- read.csv("Immunologic profiles of patients with COVID-19.csv")
setwd("C:/Users/zachr/Desktop/6970_Asn_3")
getwd()
setwd("C:/Users/zachr/Desktop/6970_Asn_3")
data <- read.csv("Immunologic profiles of patients with COVID-19.csv")
data <- read.csv("Immunologic profiles of patients with COVID-19.xlsx")
data <- read.csv("Immunologic profiles of patients with COVID-19.xlsx")
data <- read.table("Immunologic profiles of patients with COVID-19.xlsx")
library(readxl)
data <- read_xlsx("Immunologic profiles of patients with COVID-19.xlsx")
View(data)
View(data)
mean(data$BTLA)
var(data$AGE)
mean(data$AGE)
mean(data$AGE)
var(data$AGE)
sd(data$AGE)
dist(data$BTLA)
plot(data$BTLA)
hist(data$BTLA)
density(data$BTLA)
View(data)
View(data)
### --------------- SET PARAMETERS ------------------
Input_Dir <- "C:/Users/zachr/Desktop/6970_Asn_3"
Patient_filename <- "Immunologic profiles of patients with COVID-19.xlsx"
### --------------- LIBRARIES ------------------------
library(tidyverse)
library(readxl)
library(ggplot2)
library(DAAG)
library(pROC)
library(plotly)
library(glmnet)
library(caret)
## -------------- DATA CLEANING ----------------------------
#Read in data
setwd(Input_Dir)
data <- as.data.frame(read_xlsx(Patient_filename))
#Convert Sex to numeric binary outcome
data$SEX <- ifelse(data$SEX == 'F', 1, 0)
#Convert response variable to numeric binary outcome, severe = 1.
data$Severirty <- ifelse(data$Severirty == 'Severe', 1, 0)
predictors <- data %>%
dplyr::select(-`Patient Number`, -Severirty)
response <- data$Severirty
#Scale the predictors
predictors <- as.data.frame(scale(predictors))
## -------------- DATA SPLITTING ----------------------------
set.seed(1717)  #Keep it reproducibile
#Sample indices for 75% of data to uss in training
test_size <- round(dim(predictors)[1] * 0.25)
test_index <- sample.int(n = dim(predictors)[1], size = test_size, replace = FALSE)
#Subset training from selected indices
X_train <- as.matrix(predictors[-test_index, ])
Y_train <- response[-test_index]
#Subset testing data as everything not selected in sampled indices for training
X_test <- as.matrix(predictors[test_index, ])
Y_test <- response[test_index]
## -------------- MODEL TRAINING ----------------------------
#Dry run cross validation to obtain fold IDs to stroe for use throughout analysis.
fold_id_run <- cv.glmnet(X_train, Y_train, nfolds = 10, family="binomial", type.measure = "auc", keep = TRUE)
#Save the fold IDs to a variable to set later
std_foldid <- fold_id_run$foldid
alpha_values <- seq(0, 1, by=0.1)
#Initialize vectors to store AUC, threshold values, and coefficients for models
train_auc <- list()
test_auc <- list()
thresholds_train <- list()
thresholds_test <- list()
coefficients_list <- list()
#For loop for each alpha value
for (i in seq_along(alpha_values)) {
alpha <- alpha_values[i]
#Fit model using cross-validation
cvx <- cv.glmnet(X_train, Y_train, nfolds = 10, family="binomial", alpha=alpha, type.measure = "auc", foldid = std_foldid)
#Make predictions on both training and test sets using best lambda value for each alpha
prds.train <- predict(cvx, newx = X_train, type = "response", s=cvx$lambda.min)
prds.test <- predict(cvx, newx = X_test, type = "response", s=cvx$lambda.min)
#Compute and store AUC for training and test sets
roc_train <- roc(Y_train, prds.train[,1])
roc_test <- roc(Y_test, prds.test[,1])
#Apply min-max approach for training set to select best threshold
snsp_train <- cbind(roc_train$sensitivities, roc_train$specificities)
index_train_thresh <- which.max(apply(snsp_train, 1, min))
thresholds_train[i] <- roc_train$thresholds[index_train_thresh]
#Apply min-max approach on testing set to select best threshold
snsp_test <- cbind(roc_test$sensitivities, roc_test$specificities)
index_test_thresh <- which.max(apply(snsp_test, 1, min))
thresholds_test[i] <- roc_test$thresholds[index_test_thresh]
#Extract AUC's
train_auc[i] <- auc(roc_train)
test_auc[i] <- auc(roc_test)
#Extract coefficients
coefficients_for_model <- coef(cvx, s = cvx$lambda.min)
coefficients_list[[i]] <- coefficients_for_model
}
## OUR FINAL MODEL IS SELECTED AS THE BEST AUC OF ALL THE ALPHA VALUES WITH THEIR RESPECTIVE LAMBDA MINS. FROM HERE, OUR THRESHOLD SELECTION INDICATES THE BEST TRESHOLD FOR THAT SPECIFIC MODEL. THIS IS THE BEST THRESHOLD FOR THE BEST MODEL, AND WE WILL LOOK AT THE COEFFICIENTS TO DISCUSS.
## WE WILL EXAMINE RESULTS FOR BOTH TRAINING AND TESTING, BUT THE TESING IS OUR FINAL MODEL OF INTEREST FOR DISCUSSION. WE CAN COMPARE TRAINING AND TESTING CURVES FOR INTEREST AND DICSCUSSION (TESTING BETTER PERF THAN TRAINING? --> SMALL DATASET SYMPTOMS.)
#Find the index of the best model based on the test and train AUCs
best_model_index <- which.max(test_auc)
best_train_index <- which.max(train_auc)
#Look at coefficients for best testing model
best_coefficients <- coefficients_list[[best_model_index]]
best_coefficients <- as.data.frame(as.matrix(best_coefficients))
view(best_coefficients)
#Check stats for best test model
best_alpha <- alpha_values[best_model_index]
best_test_auc <- test_auc[best_model_index]
best_alpha
best_test_auc
#And for best in training
best_coefficients_train <- coefficients_list[[best_train_index]]
best_coefficients_train <- as.data.frame(as.matrix(best_coefficients_train))
view(best_coefficients_train)
best_alpha_train <- alpha_values[best_train_index]
best_train_auc <- test_auc[best_train_index]
best_alpha_train
best_train_auc
### NOTE: WE NEED TO DO LITERATURE RESEARCH ON THE BIOLOGY OF THE CYTOKINES FOR SECOND PART OF FIRST QUESTION
## -------------- PLOTTING MODELS ----------------------------
#Extract the AUC and sensitivity-specificity pairs for the best model
best_auc_train <- train_auc[best_model_index]
best_auc_test <- test_auc[best_model_index]
best_snsp_train <- cbind(roc_train$sensitivities, roc_train$specificities)
best_snsp_test <- cbind(roc_test$sensitivities, roc_test$specificities)
best_indx_train <- which.min(apply(best_snsp_train, 1, function(x) abs(x[1] - x[2])))
best_indx_test <- which.min(apply(best_snsp_test, 1, function(x) abs(x[1] - x[2])))
par(mfrow = c(1, 2), cex.main = 2, cex.lab = 1.5, cex.axis = 1.1)
plot(roc_train, main = "ROC Curve - Training", col = "blue")
abline(h = best_snsp_train[best_indx_train, 1], v = best_snsp_train[best_indx_train, 2], col = "red", lty = 2)
plot(roc_test, main = "ROC Curve - Test", col = "blue")
abline(h = best_snsp_test[best_indx_test, 1], v = best_snsp_test[best_indx_test, 2], col = "red", lty = 2)
par(mfrow=c(1,1))
par(mfrow = c(1, 2), cex.main = 1.5, cex.lab = 1.1, cex.axis = 1.1)
plot(roc_train, main = "ROC Curve - Training", col = "blue")
abline(h = best_snsp_train[best_indx_train, 1], v = best_snsp_train[best_indx_train, 2], col = "red", lty = 2)
plot(roc_test, main = "ROC Curve - Test", col = "blue")
abline(h = best_snsp_test[best_indx_test, 1], v = best_snsp_test[best_indx_test, 2], col = "red", lty = 2)
par(mfrow=c(1,1))
par(mfrow = c(1, 2), cex.main = 1.1, cex.lab = .85, cex.axis = .85)
plot(roc_train, main = "ROC Curve - Training", col = "blue")
abline(h = best_snsp_train[best_indx_train, 1], v = best_snsp_train[best_indx_train, 2], col = "red", lty = 2)
plot(roc_test, main = "ROC Curve - Test", col = "blue")
abline(h = best_snsp_test[best_indx_test, 1], v = best_snsp_test[best_indx_test, 2], col = "red", lty = 2)
par(mfrow=c(1,1))
par(mfrow = c(1, 2), cex.main = 1.1, cex.lab = .95, cex.axis = .95)
plot(roc_train, main = "ROC Curve - Training", col = "blue")
abline(h = best_snsp_train[best_indx_train, 1], v = best_snsp_train[best_indx_train, 2], col = "red", lty = 2)
plot(roc_test, main = "ROC Curve - Test", col = "blue")
abline(h = best_snsp_test[best_indx_test, 1], v = best_snsp_test[best_indx_test, 2], col = "red", lty = 2)
par(mfrow=c(1,1))
par(mfrow = c(1, 2), cex.main = 1.1, cex.lab = .95, cex.axis = .95)
plot(roc_train, main = "ROC Curve - Training", col = "violet")
abline(h = best_snsp_train[best_indx_train, 1], v = best_snsp_train[best_indx_train, 2], col = "orange", lty = 2)
plot(roc_test, main = "ROC Curve - Test", col = "violet")
abline(h = best_snsp_test[best_indx_test, 1], v = best_snsp_test[best_indx_test, 2], col = "orange", lty = 2)
par(mfrow=c(1,1))
par(mfrow = c(1, 2), cex.main = 1.1, cex.lab = .95, cex.axis = .95)
plot(roc_train, main = "ROC Curve - Training", col = "violet")
abline(h = best_snsp_train[best_indx_train, 1], v = best_snsp_train[best_indx_train, 2], col = "darkgreen", lty = 2)
plot(roc_test, main = "ROC Curve - Test", col = "violet")
abline(h = best_snsp_test[best_indx_test, 1], v = best_snsp_test[best_indx_test, 2], col = "darkgreen", lty = 2)
par(mfrow=c(1,1))
par(mfrow = c(1, 2), cex.main = 1.1, cex.lab = .95, cex.axis = .95)
plot(roc_train, main = "ROC Curve - Training", col = "violet")
abline(h = best_snsp_train[best_indx_train, 1], v = best_snsp_train[best_indx_train, 2], col = "darkorange", lty = 2)
plot(roc_test, main = "ROC Curve - Test", col = "violet")
abline(h = best_snsp_test[best_indx_test, 1], v = best_snsp_test[best_indx_test, 2], col = "darkorange", lty = 2)
par(mfrow=c(1,1))
